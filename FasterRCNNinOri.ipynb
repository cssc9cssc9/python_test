{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FasterRCNNinOri.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqE6Uc2D9uTCy0xvctLFKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2774df78ac3b4831b6484086c2c1ba9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_522f556d1a944ba09c1f299b705a473a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1d1d180e73d4a0aa676f653c2cb8c57",
              "IPY_MODEL_04ee0c9963234bf2922e0c42db608f05"
            ]
          }
        },
        "522f556d1a944ba09c1f299b705a473a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1d1d180e73d4a0aa676f653c2cb8c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_421d5d0b1d0543a293842abfeba3bb3f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 531456000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 531456000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2461df1075745579b8b737d202d19d3"
          }
        },
        "04ee0c9963234bf2922e0c42db608f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3af0812fe3dc403dbedc22dedf13cb72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 507M/507M [00:02&lt;00:00, 179MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd003948f3ad42c99cfe03cc724c0138"
          }
        },
        "421d5d0b1d0543a293842abfeba3bb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2461df1075745579b8b737d202d19d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3af0812fe3dc403dbedc22dedf13cb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd003948f3ad42c99cfe03cc724c0138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cssc9cssc9/python_test/blob/main/FasterRCNNinOri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR4iqF4AWCzn",
        "outputId": "c6b09ae5-d634-41c1-fdca-19612784493c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vT79k29EuTr",
        "outputId": "2eff8759-da99-4f73-cc35-9bfba8e861c0"
      },
      "source": [
        "!pip install ternausnet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ternausnet\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/ac/d381ef93fac89693191a39485a9eea470c5997f8b3153181e11544ac90a4/ternausnet-0.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: ternausnet\n",
            "Successfully installed ternausnet-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYpx91ljWLk5",
        "outputId": "fe681746-2bb7-43b0-b8d8-35923e07d969"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "import re\r\n",
        "import os\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "import albumentations as alb\r\n",
        "from albumentations.pytorch.transforms import ToTensor\r\n",
        "\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n",
        "from torchvision.models.detection import FasterRCNN\r\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "from torch.utils.data.sampler import SequentialSampler\r\n",
        "\r\n",
        "from glob import glob\r\n",
        "from tqdm import tqdm\r\n",
        "from collections import defaultdict\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import ternausnet.models\r\n",
        "import warnings\r\n",
        "warnings.warn('ignore')\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: ignore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdE2arCHXPTp",
        "outputId": "00a560cc-d7d1-4379-da35-86e0b55e0c03"
      },
      "source": [
        "%cd /content/drive/MyDrive/訓練資料"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/訓練資料\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2xo8Eb5UhGF",
        "outputId": "a6730fb7-af1c-4f58-8477-4021b32700fb"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'ground truth'\u001b[0m/   id_list.pkl   \u001b[01;34moriginal\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTHwZ6vqXW4t"
      },
      "source": [
        "mask_dir = os.path.join(os.getcwd(),'ground truth')\r\n",
        "img_dir = os.path.join(os.getcwd(), 'original')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtFQHS1wzTbd"
      },
      "source": [
        "import pickle\r\n",
        "# id_list = [n.split('/')[-1] for n in glob(os.path.join(img_dir,'*.jpg'))]\r\n",
        "# with open(\"id_list.pkl\",'wb') as fp:\r\n",
        "#   pickle.dump(id_list,fp)\r\n",
        "with open(\"id_list.pkl\",'rb') as fp:\r\n",
        "  id_list = pickle.load(fp)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUZw1TIB6fXS"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QbWH2QNWc2R"
      },
      "source": [
        "# Explore Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0WdERn3e4kh"
      },
      "source": [
        "def url_mask(idx):\r\n",
        "  return os.path.join(tar_dir, idx)\r\n",
        "def url_img(idx):\r\n",
        "  return os.path.join(img_dir, idx)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq-9jm3PvGrJ"
      },
      "source": [
        "transform = alb.Compose(\r\n",
        "    [\r\n",
        "     ToTensor()\r\n",
        "    ]\r\n",
        ")\r\n",
        "transform1 = alb.Compose(\r\n",
        "    [\r\n",
        "     alb.VerticalFlip(p=0.5),\r\n",
        "     alb.RandomBrightness(0.3, p=1),\r\n",
        "    #  alb.RandomCrop(256,256),\r\n",
        "     ToTensor()\r\n",
        "    ]\r\n",
        ")\r\n",
        "transform2 = alb.Compose(\r\n",
        "    [\r\n",
        "     alb.IAAAdditiveGaussianNoise(always_apply=True),\r\n",
        "     ToTensor()\r\n",
        "    ]\r\n",
        ")\r\n",
        "transform3 = alb.Compose(\r\n",
        "    [\r\n",
        "     alb.ShiftScaleRotate(shift_limit=0,rotate_limit=20,always_apply=True),\r\n",
        "     ToTensor()\r\n",
        "    ]\r\n",
        ")\r\n",
        "transform4 = alb.Compose(\r\n",
        "    [\r\n",
        "     alb.IAAAffine(shear=45),\r\n",
        "     ToTensor()\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Jp1-FxwsoX"
      },
      "source": [
        "#### Albumentations Transformation Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcTrWmDsfSjI"
      },
      "source": [
        "# idx = id_list[0]\r\n",
        "# img1 = cv2.cvtColor(cv2.imread(url_img(idx)),cv2.COLOR_BGR2RGB)\r\n",
        "# img2 = cv2.cvtColor(cv2.imread(url_tar(idx)),cv2.COLOR_BGR2RGB)\r\n",
        "# img2 = preprocessing_mask(img2)\r\n",
        "\r\n",
        "# trans = transform1(image=img1, mask=img2)\r\n",
        "# fig, ax = plt.subplots(2,2,figsize=(16,8))\r\n",
        "# ax[0,0].imshow(trans['image'])\r\n",
        "# ax[0,0].set_title('Augmented image')\r\n",
        "# ax[0,0].set_axis_off()\r\n",
        "# ax[0,1].imshow(trans['mask'])\r\n",
        "# ax[0,1].set_axis_off()\r\n",
        "# ax[0,1].set_title('Augmented mask')\r\n",
        "# ax[1,0].imshow(img1)\r\n",
        "# ax[1,1].imshow(img2)\r\n",
        "# # ax.set_axis_off()\r\n",
        "# plt.tight_layout()\r\n",
        "# plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdW0FCxc9nW1"
      },
      "source": [
        "# next(zip(transform1(image=img1, mask=img2)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naUTDWLm4dLm"
      },
      "source": [
        "#### Construct Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nok4x3IoxDuu"
      },
      "source": [
        "params={\r\n",
        "    \"model\": \"UNet11\",\r\n",
        "    'lr':0.001,\r\n",
        "    \"batch_size\":16,\r\n",
        "    \"num_workers\":2,\r\n",
        "    \"epoch\":2,\r\n",
        "    \"random_state\":18,\r\n",
        "    \"device\":device,\r\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6esyvDtJFIB"
      },
      "source": [
        "def preprocessing_mask(mask):\r\n",
        "  make = mask.astype(np.float32)\r\n",
        "  mask[mask<245] = 0\r\n",
        "  mask[mask>=245] = 255\r\n",
        "  return mask"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XaiWYVQ5kSA"
      },
      "source": [
        "class OriDataset(Dataset):\r\n",
        "  def __init__(self,dir_list, transforms=None):\r\n",
        "    super().__init__()\r\n",
        "    self.filename = dir_list\r\n",
        "    self.transforms = transforms\r\n",
        "\r\n",
        "  def __getitem__(self, idx):\r\n",
        "    image_file = self.filename[idx]\r\n",
        "\r\n",
        "    image = cv2.imread(os.path.join('/content/drive/MyDrive/訓練資料/original', image_file))\r\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\r\n",
        "\r\n",
        "    mask = cv2.imread(os.path.join('/content/drive/MyDrive/訓練資料/ground truth', image_file),cv2.IMREAD_GRAYSCALE)\r\n",
        "    mask = preprocessing_mask(mask)\r\n",
        "    mask = mask\r\n",
        "    if self.transforms:\r\n",
        "      trans = self.transforms(image=image, mask=mask)\r\n",
        "      image = trans['image']\r\n",
        "      mask = trans['mask'].squeeze\r\n",
        "      # assert(mask.shape==image.shape)\r\n",
        "\r\n",
        "    return image, mask\r\n",
        "\r\n",
        "  def __len__(self) -> int:\r\n",
        "    return len(self.filename)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0VIefa_4jHv"
      },
      "source": [
        "def create_dataloaders(id_list, params):\r\n",
        "  tr_list, val_list = train_test_split(id_list, test_size=0.2, random_state = params['random_state'])\r\n",
        "  tr_dataset0 = OriDataset(tr_list, transforms=transform)\r\n",
        "  tr_dataset1 = OriDataset(tr_list, transforms=transform1)\r\n",
        "  tr_dataset2 = OriDataset(tr_list, transforms=transform2)\r\n",
        "  # tr_dataset3 = OriDataset(tr_list, transforms=transform3)\r\n",
        "  # tr_dataset4 = OriDataset(tr_list, transforms=transform4)\r\n",
        "  tr_dataset = torch.utils.data.ConcatDataset([tr_dataset0,tr_dataset1,tr_dataset2])\r\n",
        "\r\n",
        "  val_dataset = OriDataset(val_list, transforms=transform)\r\n",
        "  tr_dataloader = DataLoader(tr_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=params['num_workers'], pin_memory=True)\r\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=params['num_workers'], pin_memory=True)\r\n",
        "  print(f'DataLoader is created! Training Dataloader size:{tr_dataset.__len__()}, Valid Dataloader size:{val_dataset.__len__()}\\n')\r\n",
        "  return tr_dataloader, val_dataloader"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc07ESRy9EIb",
        "outputId": "4358de87-b5a5-49f2-ce6c-3168a330ac54"
      },
      "source": [
        "tr_dataloader, val_dataloader = create_dataloaders(id_list, params)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataLoader is created! Training Dataloader size:65076, Valid Dataloader size:5424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxu34XWZIdLP"
      },
      "source": [
        "#### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGancLSB_sq9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2774df78ac3b4831b6484086c2c1ba9a",
            "522f556d1a944ba09c1f299b705a473a",
            "b1d1d180e73d4a0aa676f653c2cb8c57",
            "04ee0c9963234bf2922e0c42db608f05",
            "421d5d0b1d0543a293842abfeba3bb3f",
            "b2461df1075745579b8b737d202d19d3",
            "3af0812fe3dc403dbedc22dedf13cb72",
            "cd003948f3ad42c99cfe03cc724c0138"
          ]
        },
        "outputId": "d2c80977-6d39-4d4d-a2ea-992e79db4c6e"
      },
      "source": [
        "model = getattr(ternausnet.models, params[\"model\"])(pretrained=True)\r\n",
        "model = model.to(params[\"device\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-bbd30ac9.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2774df78ac3b4831b6484086c2c1ba9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=531456000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8tAFtBdEwQh"
      },
      "source": [
        "class MetricMonitor:\r\n",
        "  def __init__(self, float_precision=3):\r\n",
        "    self.float_precision = float_precision\r\n",
        "    self.reset()\r\n",
        "  \r\n",
        "  def reset(self):\r\n",
        "    self.metrics = defaultdict(lambda: {\"val\":0, \"count\":0, \"avg\":0})\r\n",
        "  \r\n",
        "  def update(self, metric_name, val):\r\n",
        "    metric = self.metrics[metric_name]\r\n",
        "\r\n",
        "    metric[\"val\"] += val\r\n",
        "    metric[\"count\"] += 1\r\n",
        "    metric['avg'] = metric['val']/metric['count']\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return \" | \".join(\r\n",
        "        [\r\n",
        "         \"{metric_name}: {avg:.{float_precision}f}\".format(\r\n",
        "             metric_name=metric_name, avg=metric['avg'], float_precision=self.float_precision\r\n",
        "         )\r\n",
        "         for (metric_name, metric) in self.metrics.items()\r\n",
        "        ]\r\n",
        "    )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU_2tAE0F39t"
      },
      "source": [
        "def train(tr_dataloader, model, criterion, optimizer, epoch, params):\r\n",
        "  metric_monitor = MetricMonitor()\r\n",
        "  model.train()\r\n",
        "  stream = tqdm(tr_dataloader)\r\n",
        "  for i, (images, target) in enumerate(stream, start=1):\r\n",
        "    images = images.to(params['device'], non_blocking=True)\r\n",
        "    target = target.to(params['device'], non_blocking=True)\r\n",
        "    output = model(images).squeeze()\r\n",
        "    loss = criterion(output, target)\r\n",
        "    metric_monitor.update(\"Loss\", loss.item())\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    stream.set_description(\r\n",
        "        \"Epoch: {epoch}. Train. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\r\n",
        "    )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eKLZbs25wQW"
      },
      "source": [
        "def validation(val_dataloader, model, criterion, epoch, params):\r\n",
        "  metric_monitor = MetricMonitor()\r\n",
        "  model.eval()\r\n",
        "  stream = tqdm(val_dataloader)\r\n",
        "  with torch.no_grad():\r\n",
        "    for i, (image, target) in enumerate(stream, start=1):\r\n",
        "      images = images.to(params['device'], non_blocking=True)\r\n",
        "      target = target.to(params['device'], non_blocking=True)\r\n",
        "      output = model(image).squeeze()\r\n",
        "      loss = criterion(output, target)\r\n",
        "      metric_monitor.update('Loss', loss.item())\r\n",
        "      stream.set_description(\r\n",
        "          \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\r\n",
        "      )"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y9mFuQX7bGm"
      },
      "source": [
        "def tr_and_val(model, tr_dataloader, val_dataloader, params):\r\n",
        "  criterion = torch.nn.BCEWithLogitsLoss().to(params['device'])\r\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=params['lr'])\r\n",
        "  for epoch in range(1, params[\"epoch\"]+1):\r\n",
        "    train(tr_dataloader, model, criterion, optimizer, epoch, params)\r\n",
        "    validation(val_dataloader, model, criterion,epoch, parms)\r\n",
        "  return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPedNkK28vEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "6d437c3d-2658-4b35-c497-c13b882c5f91"
      },
      "source": [
        "model = tr_and_val(model, tr_dataloader, val_dataloader, params)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/4068 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-eb80f604baf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_and_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-a03d1755076a>\u001b[0m in \u001b[0;36mtr_and_val\u001b[0;34m(model, tr_dataloader, val_dataloader, params)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-a0440a43967f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(tr_dataloader, model, criterion, optimizer, epoch, params)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 85, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'builtin_function_or_method'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHhnm6QQNKXK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}